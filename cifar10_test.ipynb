{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80fa6459-d47d-4fb1-8229-58a5d467a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10  # Changed from mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import bloqade\n",
    "from bloqade.ir.location import Chain, start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6156f1dd-6311-4d08-b13b-134d75aa4944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84b1bac3-4196-470f-a87b-e4c773cf9c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bloqade\n",
    "from bloqade.ir.location import Chain, start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0787924e-91cc-4b2b-8f31-59f92f4f8911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (50000, 32, 32)\n",
      "Y_train: (50000, 1)\n",
      "X_test: (10000, 32, 32)\n",
      "Y_test: (10000, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset and rescale data\n",
    "(train_X, train_y), (test_X, test_y) = cifar10.load_data()\n",
    "train_X, test_X = train_X / 255.0, test_X / 255.0\n",
    "\n",
    "# Convert to grayscale\n",
    "train_X_gray = np.mean(train_X, axis=3)\n",
    "test_X_gray = np.mean(test_X, axis=3)\n",
    "\n",
    "# Print data dimensions\n",
    "print('X_train:', train_X_gray.shape)\n",
    "print('Y_train:', train_y.shape)\n",
    "print('X_test:', test_X_gray.shape)\n",
    "print('Y_test:', test_y.shape)\n",
    "\n",
    "# Example of a training dataset image\n",
    "plt.imshow(train_X_gray[0], cmap=plt.get_cmap('gray'), interpolation='None')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b76891-831b-40bb-9f7a-708d95f3cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset and rescale data\n",
    "(train_X, train_y), (test_X, test_y) = cifar10.load_data()\n",
    "train_X, test_X = train_X / 255.0, test_X / 255.0\n",
    "\n",
    "# Convert to grayscale\n",
    "train_X_gray = np.mean(train_X, axis=3) \n",
    "test_X_gray = np.mean(test_X, axis=3)\n",
    "\n",
    "# Reshape for autoencoder\n",
    "train_X_reshape = train_X_gray.reshape(len(train_X_gray), -1)\n",
    "test_X_reshape = test_X_gray.reshape(len(test_X_gray), -1)\n",
    "\n",
    "# Hyperparameters\n",
    "dim_ae = 8  # Latent dimension for Autoencoder\n",
    "num_train_examples = 1000\n",
    "num_test_examples = 200\n",
    "\n",
    "# Prepare data\n",
    "train_X_ae = train_X_reshape[:num_train_examples]\n",
    "test_X_ae = test_X_reshape[:num_test_examples]\n",
    "\n",
    "# Autoencoder Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(256, input_dim=train_X_reshape.shape[1], activation='relu'))\n",
    "autoencoder.add(Dropout(0.3))\n",
    "autoencoder.add(Dense(128, activation='relu'))\n",
    "autoencoder.add(Dense(dim_ae, activation='linear'))\n",
    "autoencoder.add(Dense(128, activation='relu'))\n",
    "autoencoder.add(Dropout(0.3))\n",
    "autoencoder.add(Dense(256, activation='relu'))\n",
    "autoencoder.add(Dense(train_X_reshape.shape[1], activation='sigmoid'))\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the Autoencoder\n",
    "autoencoder.fit(train_X_ae, train_X_ae, \n",
    "                epochs=500, batch_size=64, \n",
    "                validation_data=(test_X_ae, test_X_ae))\n",
    "\n",
    "# Get encoded representations\n",
    "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer(index=3).output)\n",
    "xs_ae = encoder.predict(train_X_ae)\n",
    "xt_ae = encoder.predict(test_X_ae)\n",
    "\n",
    "# Scaling the AE components\n",
    "spectral_ae = np.amax(xs_ae) - np.amin(xs_ae)\n",
    "m1_ae = np.amin(xs_ae)\n",
    "xs_ae_scaled = (xs_ae - m1_ae) / spectral_ae\n",
    "xt_ae_scaled = (xt_ae - m1_ae) / spectral_ae\n",
    "\n",
    "print(\"Min AE =\", np.min(xs_ae_scaled))\n",
    "print(\"Max AE =\", np.max(xs_ae_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee6d72b-2768-43ec-8630-057af76d25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    " spectral = np.amax(xs) - np.amin(xs)\n",
    " m1 = np.amin(xs)\n",
    " xs = (xs - m1) / spectral  # to make sure values to be between [0, 1]\n",
    " xt=pca.transform(np.reshape(test_X, (10000,-1)))\n",
    " num_test_examples = 200\n",
    " xs_test = xt[:num_test_examples,:]\n",
    " xs_test = (xs_test - m1)/spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f136edd-6689-4e62-83d9-70cf5b7144ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "QRC_parameters = {\n",
    "    \"atom_number\": dim_pca,\n",
    "    \"geometry_spec\": Chain(dim_pca, lattice_spacing=10),\n",
    "    \"encoding_scale\": 9.0,\n",
    "    \"rabi_frequency\": 6.283,\n",
    "    \"total_time\": 4,\n",
    "    \"time_steps\": 8,\n",
    "    \"readouts\": \"ZZ\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a22f61-8764-4dd1-a6fa-4a6e7cbac158",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Main function for building quantum tasks.\n",
    " def build_task(QRC_parameters, xs1):\n",
    "     natoms=QRC_parameters[\"atom_number\"]\n",
    "     encoding_scale=QRC_parameters[\"encoding_scale\"]\n",
    "     dt=QRC_parameters[\"total_time\"]/QRC_parameters[\"time_steps\"]\n",
    "     #builds global Rabi and detuning pulses\n",
    "     rabi_oscillations_program = (QRC_parameters[\"geometry_spec\"]\n",
    "             .rydberg.rabi.amplitude.uniform.constant(\n",
    "                 duration=\"run_time\", value=QRC_parameters[\"rabi_frequency\"]\n",
    "             )\n",
    "             .detuning.uniform.constant(duration=\"run_time\", value=encoding_scale/2)\n",
    "             #adds local detuning according to the feature vector\n",
    "             .scale(list(xs1)).constant(duration=\"run_time\", value=-encoding_scale)\n",
    "             )\n",
    "     rabi_oscillation_job = rabi_oscillations_program.batch_assign(run_time=np.arange(1, QRC_parameters[\"time_steps\"]+1, 1)*dt)\n",
    "     #`batch_assign` used to probe the quantum reservoir at set number of timesteps\n",
    "     return rabi_oscillation_job\n",
    "\n",
    " #To obtain the embeddings, we process the report containing the collected samples into embeddins made of Z and ZZ observables.\n",
    " def process_results(QRC_parameters, report):\n",
    "     embedding=[]\n",
    "     natoms=QRC_parameters[\"atom_number\"]\n",
    "     try:\n",
    "         for t in range(QRC_parameters[\"time_steps\"]):\n",
    "             ar1=-1.0+2*((report.bitstrings())[t])\n",
    "             nsh1=ar1.shape[0]\n",
    "             for i in range(natoms):\n",
    "                 embedding.append(np.sum(ar1[:,i])/nsh1) #Z expectation values\n",
    "             if QRC_parameters[\"readouts\"]==\"ZZ\":\n",
    "                 for i in range(natoms):\n",
    "                     for j in range(i+1,natoms):\n",
    "                         embedding.append(np.sum(ar1[:,i]*ar1[:,j])/nsh1) #ZZ expectation values\n",
    "     except: #In case no experimental results were obtained.\n",
    "         print(\"No results exist.\")\n",
    "         for t in range(QRC_parameters[\"time_steps\"]):\n",
    "             for i in range(natoms):\n",
    "                 embedding.append(0.0)\n",
    "             if QRC_parameters[\"readouts\"]==\"ZZ\":\n",
    "                 for i in range(natoms):\n",
    "                     for j in range(i+1,natoms):\n",
    "                         embedding.append(0.0)\n",
    "     return embedding\n",
    "\n",
    " #Processing if only samples are needed.\n",
    " def process_results_samples(QRC_parameters, report):\n",
    "     embedding=[]\n",
    "     natoms=QRC_parameters[\"atom_number\"]\n",
    "     try:\n",
    "         embedding=report.bitstrings()\n",
    "         # for t in range(QRC_parameters[\"time_steps\"]):\\n\",\n",
    "         #     ar1=-1.0+2*((report.bitstrings())[t])\\n\",\n",
    "         #     nsh1=ar1.shape[0]\\n\",\n",
    "         #     for i in range(natoms):\\n\",\n",
    "         #         embedding.append(np.sum(ar1[:,i])/nsh1) #Z expectation values\\n\",\n",
    "         #     if QRC_parameters[\"readouts\"]==\"ZZ\":\\n\",\n",
    "         #         for i in range(natoms):\\n\",\n",
    "         #             for j in range(i+1,natoms):\\n\",\n",
    "         #                 embedding.append(np.sum(ar1[:,i]*ar1[:,j])/nsh1) #ZZ expectation values\\n\",\n",
    "     except: #In case no experimental results were obtained.\n",
    "         print(\"No results exist.\")\n",
    "         for t in range(QRC_parameters[\"time_steps\"]):\n",
    "             for i in range(natoms):\n",
    "                 embedding.append(0.0)\n",
    "             if QRC_parameters[\"readouts\"]==\"ZZ\":\n",
    "                 for i in range(natoms):\n",
    "                     for j in range(i+1,natoms):\n",
    "                         embedding.append(0.0)\n",
    "     return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f54db4a-65af-4795-8dc7-d179c37e4c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_embeddings_emulation(xs, num_examples, nshots=1000):\n",
    "    start_time = time.time()\n",
    "    result = np.array([process_results(QRC_parameters,\n",
    "        build_task(QRC_parameters, xs[data,:]).bloqade.python().run(shots=nshots, rtol=1e-8, atol=1e-8).report())\n",
    "        for data in range(num_examples)])\n",
    "    end_time = time.time()\n",
    "    print(f\"Bloqade Simulation Time: {round(end_time-start_time, 2)} seconds\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404a44bf-cef9-48aa-9438-f40266916a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=get_embeddings_emulation(xs, num_examples, nshots=1000)\n",
    "test_embeddings=get_embeddings_emulation(xs_test, num_test_examples, nshots=1000)\n",
    "\n",
    "print(embeddings.shape)\n",
    "print(test_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc71c72-f0a8-4290-8ea3-8022db89dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a linear model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#fitting to train data\n",
    "model.fit(xs, train_y[:num_examples], epochs=1000, batch_size=100, verbose=0)\n",
    "\n",
    "#evaluating on test data\n",
    "test_loss, test_acc = model.evaluate(xs_test,  test_y[:num_test_examples], verbose=0)\n",
    "print('PCA test accuracy:', 100*round(test_acc, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3cac4b-0345-40fb-8d62-efe2e86b5f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a linear model\n",
    "#we include regularization and tune epsilon parameter of the optimizer to better control training from QRC embeddings generated on finite number of samples\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, kernel_regularizer=tf.keras.regularizers.L1(l1=0.0001))\n",
    "    ])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(epsilon=0.0002),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#fitting to train data\n",
    "model.fit(embeddings, train_y[:num_examples], epochs=2000, batch_size=100, verbose=0)\n",
    "\n",
    "#evaluating on test data\n",
    "test_loss, test_acc = model.evaluate(test_embeddings,  test_y[:num_test_examples], verbose=0)\n",
    "print('QRC test accuracy:', 100*round(test_acc, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff895425-9098-4a3b-b851-40f9d0a6703d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055d3f02-9ba6-43ea-97ca-1ee3144728b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
